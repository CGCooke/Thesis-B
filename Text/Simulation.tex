\chapter{Simulation}\label{ch:Simulation}

Simulation was extensively used throughout this thesis due to the complex nature of the systems involved. 

Both hardware, and software simulation was used to understand the performance of the reciever. Hardware simulation involves the C firmware being run on the \ac{NAMURU} processor, while a Spirent GNSS simulator is used to generate a RF signal. Software simulation involves a Python model of the tracking loops being tested using synthetic data generated in software. Both forms of simulation are complemntry. Hardware simulations being the most representitive of the true performance of the reciever, however they run in real time, require a \$250,000 GNSS simulator and it can be difficult to observe the state of the tracking loops without disturbing them. Conversely, software simulations are significantly cheaper, as they run entirely on a computer. Additionally, the simulation can run as fast as the computational hardware will allow, typically 100 faster $\times$ faster. Finally, the state of the reciever can be measured without affecting the performance of the receiver.

\subsection{Hardware simulation}
The state of the reciver can be determined, both on a gross basis via NMEA output from the reciever, or on a finer basis by useing the KeaDebug feature. KeaDebug collects information about the internal state of the reciever, including the doppler frequency, phase angle, tracking mode and I and Q values. Thes values are then transmitted to a tethered laptop, where they can be stored for further analysis. One of the downsides of using the KeaDebug feature, is the potential to increase the computational load faced by the reciever. This in turn can lead to an increase in the timing jitter for collecting samples and updating the loops, which in turn increases the phase jitter. 

In particular, collecting I\&Q samples increases the computational load by 47\%, leading to the perverse phenonamyn that attempting to collect more information regarding regarding the recievers performance, leads to a degrade in performance.

\begin{table}[!htb]
\centering
\begin{tabular}{|l|l|}
\hline
\rowcolor[HTML]{C0C0C0} 
Address & Variable                                                             \\ \hline
100     & VE, E, P and L amplitudes                                            \\ \hline
\rowcolor[HTML]{EFEFEF} 
110     & Doppler frequency (units of Hz)                                      \\ \hline
120     & Delay error (Chips x 1000 )                                          \\ \hline
\rowcolor[HTML]{EFEFEF} 
130     & Channel status (1 = searching, 2 = capturing, 3 = tracking)          \\ \hline
140     & Carrier tracking mode (1 = code lock, 2 = freq lock, 3 = phase lock) \\ \hline
\rowcolor[HTML]{EFEFEF} 
150     & Satellite number                                                     \\ \hline
190     & Detected flag (1=detected, 0=not detected                            \\ \hline
\rowcolor[HTML]{EFEFEF} 
230     & Phase angle (cycles x 1024)                                          \\ \hline
240     & Differential phase angle (cycles x 1024)                             \\ \hline
\rowcolor[HTML]{EFEFEF} 
260     & Detection threshold                                                  \\ \hline
270     & False frequency metric                                               \\ \hline
\rowcolor[HTML]{EFEFEF} 
280     & Coherent integration period (4 ms when tracking)                     \\ \hline
290     & Number of non-coherent rounds (8 when tracking)                      \\ \hline
\rowcolor[HTML]{EFEFEF} 
340     & Prompt in-phase sample (I)                                           \\ \hline
350     & Prompt quadrature phase sample (Q)                                   \\ \hline
\end{tabular}
\caption{KeaDebug variables avalible for dumping to a host computer.}
\label{tab:KeaDebugKey}
\end{table}

\begin{figure}[!htb] 
    \centering
    \includegraphics[width=1\textwidth]{Simulations/SpirentSatelliteMap.bmp} 
    \caption{}
    \label{fig:SpirentSatelliteMap}
\end{figure}


\begin{figure}[!htb] 
    \centering
    \includegraphics[width=1\textwidth]{mywork/Spirent-GSS8000.jpg} 
    \caption{An example of a Spirent \ac{GPS} simulator. The actual model used for this research differs from the one pictured. The simulator is controlled by a tethered computer, which runs the \emph{SimGen} software, pictured in figure \ref{:HighGScreenshot}.}
    \label{fig:Spirent}
\end{figure}


\begin{figure}[!htb] 
    \centering
    \includegraphics[width=1\textwidth]{mywork/Spirent-GSS8000.jpg} 
    \caption{An example of a Spirent \ac{GPS} simulator. The actual model used for this research differs from the one pictured. The simulator is controlled by a tethered computer, which runs the \emph{SimGen} software, pictured in figure \ref{:HighGScreenshot}.}
    \label{fig:Spirent}
\end{figure}

\begin{figure}[!htb] 
    \centering
    \includegraphics[width=1\textwidth]{mywork/HighGScreenshot.png} 
    \caption{The SimGen software, used to define scenarios and control the \ac{GNSS} simulator.}
    \label{:HighGScreenshot}
\end{figure}


The correct performance of a \ac{PLL} can be examined by attempting to decode the navigation message transmitted by the satellite. Other, more sophisticated methods for determining if the  receiver is in phase lock, will be examined in Thesis B. In figures \ref{fig:RawSignal} and \ref{fig:DigitalSignal}, the decoded message can be clearly seen, indicating that the receiver is maintaining phase lock with the signal.

\subsection{Software simulation}
\ref{ch:Code}

A software based receiver has been developed as part of the thesis, in order to gain a greater understanding of the performance of tracking loops on real world data. 

The software receiver was developed in Python, based on the authors previous experience with the language, as well the need to interface with domain specific libraries.  The approach of using an \ac{GNSS}, and testing in software was effectively used by Kazemi \cite{KazemiPHD} in order to critically evaluate the performance of the new tracking loops developed as part of his PHD. Ward also used Montecarlo simulations in order to ascertain the performance limits of his FLL/PLL combined tracking loop.

A signal was generated by a Spirent \ac{GPS} simulator, which can be seen in figure \ref{fig:Spirent}. This signal was then digitised using a NordNav \ac{SDR}, with a sampling rate of $16.3676 \times 10^6$ samples per second. 

A range of simulations were created in order to better understand the performance of the software receiver. In particular, scenarios for 0g, 1g, 2g, 5g, 7.5g and 10g were created. In figure \ref{fig:Doppler}, the output from the \ac{NCO} of the software receiver can be seen. In the simulation, the receiver remains stationary until 8s, at which point it starts accelerating directly upwards at 10g, creating a ramp in the \ac{NCO} frequency. It is important to note that while the receiver is accelerating at 10g, the \ac{LOS} dynamics may only be 5g. 


\section{Airborne experiment}

\begin{figure}[!htb] 
    \centering
    \includegraphics[width=1\textwidth]{mywork/SeminoleBankingPRjpg.jpg} 
    \caption{A Piper PA-44 Seminole.}
    \label{fig:PiperSeminole}
\end{figure}

A real-world data-set was processed, consisting of data taken captured a flight aboard a UNSW Aviation Piper PA-44 Seminole VH-FRI. Data from the flight was captured by a NordNav IF Recorder, and processed using the the software receiver. 

The actual carrier doppler shift, as measured by taking the finite difference of the satellite pseudoranges, and converted to Hz, was compared against the measured Doppler shift in the software receiver. There is a small offset because of drift in the receiver crystal. The results of this experiment can be see in figure \ref{fig:SimulatedDynamics}. While the dynamics experienced by the receiver were on the order of $\pm 5m/s^2$, somewhat less than the dynamics that are experienced by a \ac{LV}, This experiment is important, as it verifies the real world performance of the soft receiver. 


